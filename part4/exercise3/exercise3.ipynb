{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht 4.3: de Goldberg-Variationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De [Goldberg-variationen (BWV 988)](https://de.wikipedia.org/wiki/Goldberg-Variationen) is een muziekstuk dat rondom 1741 door [Johann Sebastian Bach](https://de.wikipedia.org/wiki/Johann_Sebastian_Bach) geschreven is. Het betreft een Aria met een dertigtal variaties hier op. De naam van het werk is anekdotisch: hierin wordt gesuggereert dat Bach het werk schreef voor [Johann Gottlieb Goldberg](https://de.wikipedia.org/wiki/Johann_Gottlieb_Goldberg), de muziekleraar van [graaf Hermann Carl von Keyserlinkgk](https://de.wikipedia.org/wiki/Hermann_Carl_von_Keyserlingk), opdat deze zijn slapeloze nachten wat prettiger door kon komen. Hoewel het werk oorspronkelijk voor clavicimbel geschreven is, wordt het ook vaak op de piano uitgevoerd ([hier](https://www.youtube.com/watch?v=p4yAB37wG5s) bijvoorbeeld door niemand minder dan [Glenn Gould](https://nl.wikipedia.org/wiki/Glenn_Gould))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze opgave gaan we met een RNN een eenendertigste variatie aan dit werk toevoegen. Er zijn natuurlijk verschillende manieren om dit probleem te adresseren. We zouden bijvoorbeeld de partituur kunnen scannen en op basis van beeldherkenning en -generatie hier een tweetal nieuwe pagina's aan toevoegen.\n",
    "\n",
    "Hier kiezen we er evenwel voor om de bladmuziek om te zetten in een tekstuele representatie. Dan wordt het maken van een nieuwe variatie feitelijk een kwestie van tekstgeneratie, waar LSTM's en GRU's goed in zijn. Er zijn gelukkig verschillende technieken om dit te doen (zie met name [Marinescu, 2019](https://doi.org/10.1016/j.procs.2019.09.166)), maar we gebruiken hier de midi-bestanden [van Dave's J.S. Bach page](http://www.jsbach.net/midi/midi_goldbergvariations.html) die we met behulp van [py_midicsv](https://pypi.org/project/py_midicsv/) hebben omgezet in csv-bestanden: één bestand voor elke variatie. Je vindt deze bestanden in [de zip `data/bwv988.zip`](data/bwv988.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de cellen hieronder staan de verschillende onderdelen toegelicht. In grote lijnen ziet het stappenplan er als volgt uit:\n",
    "\n",
    "0. importeer de noodzakelijke bibliotheken (om uiteindelijk de muziek te kunnen horen moet je waarschijnlijk [py_midicsv](https://pypi.org/project/py_midicsv/) nog even pip installen)\n",
    "1. laad de databestanden in één grote lijst\n",
    "2. preprocess de data\n",
    "3. maak de vectoren `x` en de `y` en one-hot-encode deze\n",
    "4. maak en train het model\n",
    "5. maak een methode die op basis van een `seed` een nieuwe sequentie genereert af\n",
    "6. zet die nieuwe sequentie om in een midi-bestand en geniet van de nieuwe variatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 0: importeer de noodzakelijke bibliotheken en afhankelijkheden\n",
    "\n",
    "Run de onderstaande cel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:33.657622Z",
     "start_time": "2024-10-13T17:58:33.654492Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from part4.utils import *"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: imporeer de data\n",
    "\n",
    "Pak de zip met de data uit in de directory `data` (of ergens anders wat voor je werkt). Dit zijn csv-versies van de midi-bestanden die we van [Dave's J.S. Bach page](http://www.jsbach.net/midi/midi_goldbergvariations.html) hebben afgehaald – bekijk de individuele bestanden om een beeld te krijgen van hoe die dingen eruit zien. Loop door al deze bestanden en laad de inhoud hiervan in de lijst `data`. Je kunt gebruik maken van [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:34.665404Z",
     "start_time": "2024-10-13T17:58:34.452361Z"
    }
   },
   "source": [
    "data = []\n",
    "\n",
    "# Code for bach\n",
    "files = Path(\"data/bwv988\").rglob(\"*.txt\")\n",
    "for file in files:\n",
    "    data.append(file.read_text())\n",
    "\n",
    "# # Code for NGGYU\n",
    "# file = Path(\"data/nggyu.txt\")\n",
    "# data.append(file.read_text())\n"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:34.999850Z",
     "start_time": "2024-10-13T17:58:34.995749Z"
    }
   },
   "source": [
    "len(data) # zou 31 moeten zijn (de aria en dertig variaties)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: preprocessing\n",
    "\n",
    "Het preprocessen van de data kent op zich weer een aantal stappen. Omdat we uiteindelijk een karakter-gebaseerde sequentie-generator gaan maken, is het van belang om een lijstje te hebben van alle *unieke* karakters die in de data voorkomen. Verder moeten we die karakters om kunnen zetten in getallen, omdat we die getallen aan het model gaan voeren; en om uiteindelijk de tonen (karakters) weer terug te kunnen krijgen, moeten we ook die getallen weer om kunnen zetten in de corresponderende karakters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:36.539399Z",
     "start_time": "2024-10-13T17:58:36.534080Z"
    }
   },
   "source": [
    "chars = sorted(list(set(\"\".join(data))))\n",
    "char_to_idx = { char: i for i, char in enumerate(chars) }\n",
    "idx_to_char = { i: char for char, i in char_to_idx.items() }\n"
   ],
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:37.003663Z",
     "start_time": "2024-10-13T17:58:36.998421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to encoding.json\n",
    "import json\n",
    "import string\n",
    "\n",
    "# Write encoding to json file\n",
    "codes = (string.digits + string.ascii_letters +\n",
    "         string.punctuation).replace('\\\\', '').replace('\"', '').replace('\\'', '')[:88]\n",
    "\n",
    "note_range = list(range(21, 109))\n",
    "note_to_enc = dict(zip(note_range, codes))\n",
    "\n",
    "with open('encoding.json', 'w') as f:\n",
    "    json.dump(note_to_enc, f)\n",
    "    \n",
    "# Source: Tobias van der Werf\n"
   ],
   "outputs": [],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:37.713115Z",
     "start_time": "2024-10-13T17:58:37.708879Z"
    }
   },
   "source": [
    "print(len(chars)) # zou 55 moeten opleveren: wat representeert dit aantal?\n",
    "\n",
    "\"\"\"\n",
    "Het getal representeert het aantal unieke karakters in de data.\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHet getal representeert het aantal unieke karakters in de data.\\n'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we karakters kunnen vertalen in getallen, kunnen we de data omzetten in de corresponderende indexen."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:39.377840Z",
     "start_time": "2024-10-13T17:58:39.351030Z"
    }
   },
   "source": "encoded_sequence = [char_to_idx[char] for char in \"\".join(data)]\n",
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:39.922988Z",
     "start_time": "2024-10-13T17:58:39.918723Z"
    }
   },
   "source": [
    "len(encoded_sequence) # zou 309378 moeten opleveren"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309378"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de cel hieronder zetten we twee waarden die we verderop nodig hebben. Je kunt eventueel experimenteren met verschillende lenges van `sequence_length`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:41.110939Z",
     "start_time": "2024-10-13T17:58:41.107088Z"
    }
   },
   "source": [
    "vocab_size = len(chars)\n",
    "sequence_length = 64  \n"
   ],
   "outputs": [],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3: matrixen, vectoren en one hot encoding\n",
    "\n",
    "Maak nu de data-matrix `X` en de target-vector `y` op dezelfde manier als we hebben gedaan in opgave 4.2, bij die `n-grams`. Zie eventueel hetzelfde plaatje hieronder. Net als bij opgave 4.2 kun je hier prima standaard python-lijsten voor gebruiken; we zetten ze later om in numpy-datatypen.\n",
    "\n",
    "![n-grams](imgs/n-gram.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:44.908622Z",
     "start_time": "2024-10-13T17:58:43.227137Z"
    }
   },
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(encoded_sequence) - sequence_length):\n",
    "    X.append(encoded_sequence[i:i + sequence_length])\n",
    "    y.append(encoded_sequence[i + sequence_length])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zet nu `X` en `y` om in one-hot encoded matrices met een breedte van `vocab_size`. Maak gebruik van [`tf.keras.utils.to_categorical`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) (of je eigen uitwerking uit week 2)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:52.192035Z",
     "start_time": "2024-10-13T17:58:46.988499Z"
    }
   },
   "source": [
    "X = to_categorical(X, num_classes=vocab_size)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 4: maken en trainen van het model\n",
    "\n",
    "Als model maken we gebruik van een recurrent LSTM netwerk – gebruik de relevante klassen uit [`Keras.layers`](https://keras.io/api/layers/). Gebruik een [`Input`]() als eerste laag (bedenk zelf wat de correcte waarden voor de `shape`-parameter zijn). Voeg minimaal *twee* [`LSTM-layers`](https://keras.io/api/layers/recurrent_layers/lstm/) toe en zorg ervoor dat de laatste *state* hiervan aan de output wordt meegegeven - bestudeer de documentatie om te zien hoe je dat moet doen. Voeg als laatste laag een [`Dense`](https://keras.io/api/layers/core_layers/dense/) toe met een grootte van `vocab_size` en 'softmax' als activatie-functie. Vergewis je ervan dat je begrijpt waarom je juist deze waarden moet gebruiken."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:52.937042Z",
     "start_time": "2024-10-13T17:58:52.248041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(sequence_length, vocab_size)),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:58:53.043570Z",
     "start_time": "2024-10-13T17:58:53.009759Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_12 (\u001B[38;5;33mLSTM\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │        \u001B[38;5;34m94,208\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (\u001B[38;5;33mLSTM\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001B[38;5;33mLSTM\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m55\u001B[0m)             │         \u001B[38;5;34m7,095\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">94,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,095</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m364,471\u001B[0m (1.39 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">364,471</span> (1.39 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m364,471\u001B[0m (1.39 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">364,471</span> (1.39 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 133
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik nu de methode `fit` om het model te trainen. Kies relevante opties voor `epochs` en voor `batch_size`. __Let op:__ het trainen van het netwerk kan even duren. Op mijn macbook air uit 2020 met een M1-processor duurde één epoch een kleine vier minuten ⏳."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:50:13.845598Z",
     "start_time": "2024-10-13T17:50:13.699610Z"
    }
   },
   "source": [
    "model.fit(X, y, epochs=10, batch_size=64)\n",
    "# model = load_model(\"../models/bach-nggyu.keras\")"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 5: Nieuwe karakters voorspellen\n",
    "\n",
    "Maak nu de methode `sample` hieronder af. Deze methode krijg een `seed` mee die in het getrainde model gestopt wordt. Dit model voorspelt op basis van deze `seed` de verdeling van de waarschijnlijkheid van alle karakters uit `vocab`. Het stappenplan voor deze methode is als volgt:\n",
    "\n",
    "1. one-hot encode de geëncodeerde `seed`\n",
    "2. gebruik `model.predict` om de index van het volgende karakter te voorspellen\n",
    "3. maak gebruik van `utils.add_temperatature` om het geheel iets stochastischer (en dus interessanter) te maken\n",
    "4. kies één van de indexen uit de voorspelling, op basis van de distributie die het model heeft gegeven (bestudeer de documentatie van [`numpy.random.choice`]() om te zien hoe je dit eenvoudig kunt doen.\n",
    "5. zet deze gekozen index om in het corresponderende karakter uit `vocab` - maak gebruik van de dictionary `idx_to_char` die je hierboven hebt gemaakt.\n",
    "6. voeg dit karakter toe aan de gegenereerde tekst\n",
    "7. voeg de gekozen index toe aan `encoded_seed` en verwijder, om de grootte constant te houden, het eerste karakter.\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:48:23.693467Z",
     "start_time": "2024-10-13T15:48:23.637785Z"
    }
   },
   "cell_type": "code",
   "source": "# model.save(\"../models/bach-nggyu.keras\")",
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:49:50.907676Z",
     "start_time": "2024-10-13T15:49:50.903680Z"
    }
   },
   "source": [
    "def sample(model, seed_text, num_generate, temperature=1.0):\n",
    "    generated_text = seed_text\n",
    "    encoded_seed = [char_to_idx[char] for char in seed_text]\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        X = to_categorical([encoded_seed], num_classes=vocab_size)\n",
    "        \n",
    "        predictions = model.predict(X, verbose=0)\n",
    "        predictions = add_temperature(predictions, temperature)\n",
    "        \n",
    "        idx = np.random.choice(range(vocab_size), p=predictions[0])\n",
    "        generated_text += idx_to_char[idx]\n",
    "        \n",
    "        encoded_seed.append(idx)\n",
    "        encoded_seed = encoded_seed[1:]\n",
    "\n",
    "    return generated_text\n"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 6: een nieuwe variatie\n",
    "\n",
    "Gebruik nu de eerste paar maten van een variatie, of van de aria zelf, om met behulp van `sample` een nieuwe variatie te maken. Kies een relevante waarde voor `num_generate` zodat je voor een paar minuten karakters terugkrijgt. __Let op:__ Het genereren van een fatsoenlijk stuk kan ook wel even duren. \n",
    "\n",
    "Sla het gegenereerde bestand op en gebuik de scripts `deprocess.py` en `csvtomidi.py` om het uiteindelijke midi-bestand te creëren. Zie het voorbeeld hieronder (ervan uitgaande dat het gegenereerde bestand is opgeslagen onder de naam `result.txt`):\n",
    "\n",
    "```shell\n",
    "python deprocess.py -i result.txt -o tmp.txt --tempo 250000\n",
    "python csvtomidi.py -i tmp.txt -o variatie31.mid\n",
    "```\n",
    "\n",
    "Je kunt midi afspelen met VLC, of je kunt het online omzetten naar bijvoorbeeld mp3. Speel het af en geniet van je eigen bach-creatie 🎼🎶.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:55:50.687869Z",
     "start_time": "2024-10-13T17:50:17.627494Z"
    }
   },
   "source": [
    "seed_text = \"yW yW yW yW yW yW yW yW yW yW yW yW yW yW yW yW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCW yCFY yCFY yCFW yCFW yCFY yCFY yCFY yCFY yCFY yCFY yCFY yCFY yCF! yCF! yCF! yCF!\"\n",
    "\n",
    "generated_text = sample(model, seed_text, 5000)\n",
    "with open(\"result.txt\", \"w\") as f:\n",
    "    f.write(generated_text)\n"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verdere stappen\n",
    "\n",
    "Misschien vind je de nieuwe variatie nog niet zo heel fraai – misschien wel een beetje *John Cage meets JS Bach*. Je kunt proberen het model wat uit te breiden (bijvoorbeeld door een [`GRU`]() laag toe te voegen), de `sequence_length` te vergroten of meer of juist minder karakters te genereren. Experimenteer hier wat mee en bekijk (of beluister eigenlijk) wat het schoonste resultaat oplevert. Of je kunt natuurlijk meer bestanden van Dave's JS Bach Page halen en kijken of je een heel nieuw werk kunt genereren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credits**\n",
    "\n",
    "Deze opgave is gemaakt op basis van [het genoemde artikel van Alexandru-Ion Marinescu](https://doi.org/10.1016/j.procs.2019.09.166) en een vergelijkbaar experiment van [Tobias van der Werf](https://github.com/tobiasvanderwerff)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
